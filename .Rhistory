QUA1=quantile(JP_Sales,1/4),
QUA3=quantile(JP_Sales,3/4),
IQR=IQR(JP_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Other_Sales)==1),
is_NOT_NULL=sum(!is.na(Other_Sales)==1)
)
df %>%
filter(!is.na(Other_Sales))%>%
summarise(
Max=max(Other_Sales),
Min=min(Other_Sales),
Mean=mean(Other_Sales),
Median=median(Other_Sales),
QUA1=quantile(Other_Sales,1/4),
QUA3=quantile(Other_Sales,3/4),
IQR=IQR(Other_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Global_Sales)==1),
is_NOT_NULL=sum(!is.na(Global_Sales)==1)
)
df%>%
filter(!is.na(Global_Sales))%>%
summarise(
Max=max(Global_Sales),
Min=min(Global_Sales),
Mean=mean(Global_Sales),
Median=median(Global_Sales),
QUA1=quantile(Global_Sales,1/4),
QUA3=quantile(Global_Sales,3/4),
IQR=IQR(Global_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Critic_Score)==1),
is_NOT_NULL=sum(!is.na(Critic_Score)==1)
)
df %>%
filter(!is.na(Critic_Score))%>%
summarise(
Max=max(Critic_Score),
Min=min(Critic_Score),
Mean=mean(Critic_Score),
Median=median(Critic_Score),
QUA1=quantile(Critic_Score,1/4),
QUA3=quantile(Critic_Score,3/4),
IQR=IQR(Critic_Score)
)
df %>%
summarise(is_NULL=sum(is.na(Critic_Count)==1),
is_NOT_NULL=sum(!is.na(Critic_Count)==1)
)
df %>%
filter(!is.na(Critic_Count))%>%
summarise(
Max=max(Critic_Count),
Min=min(Critic_Count),
Mean=mean(Critic_Count),
Median=median(Critic_Count),
QUA1=quantile(Critic_Count,1/4),
QUA3=quantile(Critic_Count,3/4),
IQR=IQR(Critic_Count)
)
df %>%
summarise(is_NULL=sum(is.na(User_Score)==1),
is_NOT_NULL=sum(!is.na(User_Score)==1),
is_tbd=sum(User_Score=="tbd")
)
df %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!is.na(User_Score) & User_Score!="tbd") %>%
summarise(
Max=max(User_Score),
Min=min(User_Score),
Mean=mean(User_Score),
Median=median(User_Score),
QUA1=quantile(User_Score,1/4),
QUA3=quantile(User_Score,3/4),
IQR=IQR(User_Score)
)
df %>%
summarise(is_NULL=sum(is.na(User_Count)==1),
is_NOT_NULL=sum(!is.na(User_Count)==1)
)
df %>%
filter(!is.na(User_Count))%>%
summarise(
Max=max(User_Count),
Min=min(User_Count),
Mean=mean(User_Count),
Median=median(User_Count),
QUA1=quantile(User_Count,1/4),
QUA3=quantile(User_Count,3/4),
IQR=IQR(User_Count)
)
summary(df)
outlier_global_sales <- qplot(y = Global_Sales, ylab = "Outliers Global Sales", data = df, geom = "boxplot", fill=I("tomato")) + theme_minimal() + theme(axis.text.x = element_text(angle = 90))
outlier_global_sales
df = subset(df, select = -c(NA_Sales,EU_Sales,JP_Sales,Other_Sales))
df <- subset(df, df$Platform != "PCFX")
df <- subset(df, df$Platform != "GG")
df$Year_of_Release <- 2024 - df$Year_of_Release
names(df)[3] <- "Age"
df <- subset(df, df$Name != "" | df$Genre != "")
is.na(df) <- df == ''
df$User_Score <- as.character(df$User_Score)
df$User_Score[df$User_Score == "tbd"] <- ""
plot_missing(df)
# Convert categorical to numbers
df$User_Score=as.double(df$User_Score)
df_imputation <- data.frame(df$Age, df$Rating, df$Critic_Score, df$Critic_Count, df$User_Score, df$User_Count)
names(df_imputation) <- c("Age_imp","Rating_imp", "Critic_Score_imp", "Critic_Count_imp", "User_Score_imp", "User_Count_imp")
df_imputation$Rating_imp = factor(df_imputation$Rating_imp,
levels = c('AO', 'E', 'E10+', 'EC', 'K-A', 'M', 'RP', 'T'), labels = c(1, 2, 3, 4, 5, 6, 7, 8))
# Imputation w/ MICE
md.pattern(df_imputation)
df_imputation_imp <- mice(df_imputation, m=5, seed = 123)
df_imputation <- complete(df_imputation_imp, 1)
plot_missing(df_imputation)
# Revert numbers to categorical
df_imputation$Rating_imp = factor(df_imputation$Rating_imp,
levels = c(1, 2, 3, 4, 5, 6, 7, 8), labels = c('AO', 'E', 'E10+', 'EC', 'K-A', 'M', 'RP', 'T'))
df <- df %>% mutate(ID = row_number())
df_imputation <- df_imputation %>% mutate(ID = row_number())
df <- merge(df,df_imputation,by="ID")
df = subset(df, select = -c(ID, Rating, Age, Critic_Score, Critic_Count, User_Score, User_Count))
publisher_data <- df %>%
group_by(Publisher) %>%
summarise(count = n()) %>%
top_n(n = 10, wt = count)
publisher_charts <- ggplot(publisher_data, aes(x = Publisher, y = count, fill=count)) + geom_col(fill="orange")+
labs(title = "Top 10 Publisher", x="Publisher",y="Total") + coord_flip()
publisher_charts
genre_data <- df %>%
group_by(Genre) %>%
summarise(count = n()) %>%
top_n(n = 5, wt = count)
genre_charts <- ggplot(genre_data, aes(x = Genre, y = count, fill=count)) + geom_col(fill="red")+
labs(title = "Top 5 Genres", x="Genre",y="Total")
genre_charts
platform_data <- df %>%
group_by(Platform) %>%
summarise(count = n()) %>%
top_n(n = 5, wt = count)
platform_charts <- ggplot(platform_data, aes(x = Platform, y = count, fill=count)) + geom_col(fill="yellow")+
labs(title = "Top 5 Platform", x="Platform",y="Total")
platform_charts
qplot(x = Genre, data = df) + geom_bar(fill = "purple") + coord_flip()  + facet_wrap(~Rating_imp, nrow = 2)
qplot(x=Platform,data=df)+ geom_bar(fill="navy") + theme(axis.text = element_text) + coord_flip() + theme_minimal() + facet_wrap(~Genre,nrow=1)
qplot(x=Platform,data=df)+ geom_bar(fill="brown") + theme(axis.text = element_text) + coord_flip() + theme_minimal() + facet_wrap(~Rating_imp,nrow=1)
cor_df <- data.frame(df$Age_imp, df$Critic_Score_imp, df$Critic_Count_imp, df$User_Score_imp, df$User_Count_imp, df$Global)
cor_matrix<-cor(cor_df)
corrplot(cor_matrix, diag = FALSE, order = "FPC", tl.pos = "td", tl.cex = 0.5, method = "circle",type="upper")
df1 = subset(df, select = -c(Name, Publisher, Developer))
# Exp 1 - train:test 70:30, seed 555
set.seed(555)
split = sample.split(df1$Global, SplitRatio = 0.7)
train_dataset1 = subset(df1, split == TRUE)
test_dataset1 = subset(df1, split == FALSE)
# Exp 2 - train:test 70:30, seed 555, outliers removed, data scaling
Q <- quantile(df1$Global_Sales, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(df1$Global_Sales)
df1_clean<- subset(df1, df1$Global_Sales > (Q[1] - 1.5*iqr) & df1$Global_Sales < (Q[2]+1.5*iqr))
set.seed(555)
split = sample.split(df1_clean$Global, SplitRatio = 0.7)
train_dataset2 = subset(df1_clean, split == TRUE)
test_dataset2 = subset(df1_clean, split == FALSE)
train_dataset2[,3] = scale(train_dataset3[,3], center = TRUE, scale = TRUE)
# Exp 2 - train:test 70:30, seed 555, outliers removed, data scaling
Q <- quantile(df1$Global_Sales, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(df1$Global_Sales)
df1_clean<- subset(df1, df1$Global_Sales > (Q[1] - 1.5*iqr) & df1$Global_Sales < (Q[2]+1.5*iqr))
set.seed(555)
split = sample.split(df1_clean$Global, SplitRatio = 0.7)
train_dataset2 = subset(df1_clean, split == TRUE)
test_dataset2 = subset(df1_clean, split == FALSE)
train_dataset2[,3] = scale(train_dataset2[,3], center = TRUE, scale = TRUE)
test_dataset2[,3] = scale(test_dataset2[,3], center = TRUE, scale = TRUE)
train_dataset2[,6:9] = scale(train_dataset2[,6:9], center = TRUE, scale = TRUE)
test_dataset2[,6:9] = scale(test_dataset2[,6:9], center = TRUE, scale = TRUE)
### Exp 1 - Multiple Linear Regression
regressor1 = lm(formula = Global_Sales ~ .,
data = train_dataset1)
summary(regressor1)
summ(regressor1, confint = TRUE)
y1 = predict(regressor1, train_dataset1)
table(y1, train_dataset1$Global_Sales)
y_pred1 = predict(regressor1, test_dataset1)
table(y_pred1, test_dataset1$Global_Sales)
# RMSE on training set
RMSE(y1, train_dataset1$Global_Sales)
# RMSE on test set
RMSE(y_pred1, test_dataset1$Global_Sales)
# MAE train dataset
MAE(y1, train_dataset1$Global_Sales)
# MAE test dataset
MAE(y_pred1, test_dataset1$Global_Sales)
### Exp 2 - Multiple Linear Regression
regressor2 = lm(formula = Global_Sales ~ .,
data = train_dataset2)
summary(regressor2)
summ(regressor2, confint = TRUE)
y2 = predict(regressor2, train_dataset2)
table(y2, train_dataset2$Global_Sales)
y_pred2 = predict(regressor2, test_dataset2)
table(y_pred2, test_dataset2$Global_Sales)
# RMSE on training set
RMSE(y2, train_dataset2$Global_Sales)
# RMSE on test set
RMSE(y_pred2, test_dataset2$Global_Sales)
# MAE train dataset
MAE(y2, train_dataset2$Global_Sales)
# MAE test dataset
MAE(y_pred2, test_dataset2$Global_Sales)
quarto install tinytex
install.packages('tinytex')
tinytex::install_tinytex()
# Importing Libraries
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(corrplot)
library(broom)
library(DataExplorer)
library(gridExtra)
library(caret)
library(RColorBrewer)
library(missForest)
library(caTools)
library(jtools)
library(mice)
library(randomForest)
library(e1071)
library(ROCR)
library(klaR)
library(readr)
df <- read_csv("C:/Users/21697/OneDrive/Bureau/Video_Games_Sales_as_at_22_Dec_2016.csv")
dim(df)
spec(df)
head(df)
df$Platform=as.factor(df$Platform)
df$Genre=as.factor(df$Genre)
df$Publisher=as.factor(df$Publisher)
df$Developer=as.factor(df$Developer)
df$Rating=as.factor(df$Rating)
df$Year_of_Release=as.numeric(df$Year_of_Release)
df %>% summarise(n_distinct(Name))
df %>%   group_by(Platform) %>%   summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%   arrange(desc(Count))
df %>%
group_by(Genre) %>%
summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%
arrange(desc(Count))
df %>%
group_by(Publisher) %>%
summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%
arrange(desc(Count))
df %>%
group_by(Developer) %>%
summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%
arrange(desc(Count))
df %>%
group_by(Rating) %>%
summarise(Count = n(),Perc=round(n()/nrow(.)*100,2)) %>%
arrange(desc(Count))
df %>%
summarise(is_NULL=sum(is.na(NA_Sales)==1),
is_NOT_NULL=sum(!is.na(NA_Sales)==1)
)
df%>%
filter(!is.na(NA_Sales))%>%
summarise(
Max=max(NA_Sales),
Min=min(NA_Sales),
Mean=mean(NA_Sales),
Median=median(NA_Sales),
QUA1=quantile(NA_Sales,1/4),
QUA3=quantile(NA_Sales,3/4),
IQR=IQR(NA_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(EU_Sales)==1),
is_NOT_NULL=sum(!is.na(EU_Sales)==1)
)
df%>%
filter(!is.na(EU_Sales))%>%
summarise(
Max=max(EU_Sales),
Min=min(EU_Sales),
Mean=mean(EU_Sales),
Median=median(EU_Sales),
QUA1=quantile(EU_Sales,1/4),
QUA3=quantile(EU_Sales,3/4),
IQR=IQR(EU_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(JP_Sales)==1),
is_NOT_NULL=sum(!is.na(JP_Sales)==1)
)
df %>%
filter(!is.na(JP_Sales))%>%
summarise(
Max=max(JP_Sales),
Min=min(JP_Sales),
Mean=mean(JP_Sales),
Median=median(JP_Sales),
QUA1=quantile(JP_Sales,1/4),
QUA3=quantile(JP_Sales,3/4),
IQR=IQR(JP_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Other_Sales)==1),
is_NOT_NULL=sum(!is.na(Other_Sales)==1)
)
df %>%
filter(!is.na(Other_Sales))%>%
summarise(
Max=max(Other_Sales),
Min=min(Other_Sales),
Mean=mean(Other_Sales),
Median=median(Other_Sales),
QUA1=quantile(Other_Sales,1/4),
QUA3=quantile(Other_Sales,3/4),
IQR=IQR(Other_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Global_Sales)==1),
is_NOT_NULL=sum(!is.na(Global_Sales)==1)
)
df%>%
filter(!is.na(Global_Sales))%>%
summarise(
Max=max(Global_Sales),
Min=min(Global_Sales),
Mean=mean(Global_Sales),
Median=median(Global_Sales),
QUA1=quantile(Global_Sales,1/4),
QUA3=quantile(Global_Sales,3/4),
IQR=IQR(Global_Sales)
)
df %>%
summarise(is_NULL=sum(is.na(Critic_Score)==1),
is_NOT_NULL=sum(!is.na(Critic_Score)==1)
)
df %>%
filter(!is.na(Critic_Score))%>%
summarise(
Max=max(Critic_Score),
Min=min(Critic_Score),
Mean=mean(Critic_Score),
Median=median(Critic_Score),
QUA1=quantile(Critic_Score,1/4),
QUA3=quantile(Critic_Score,3/4),
IQR=IQR(Critic_Score)
)
df %>%
summarise(is_NULL=sum(is.na(Critic_Count)==1),
is_NOT_NULL=sum(!is.na(Critic_Count)==1)
)
df %>%
filter(!is.na(Critic_Count))%>%
summarise(
Max=max(Critic_Count),
Min=min(Critic_Count),
Mean=mean(Critic_Count),
Median=median(Critic_Count),
QUA1=quantile(Critic_Count,1/4),
QUA3=quantile(Critic_Count,3/4),
IQR=IQR(Critic_Count)
)
df %>%
summarise(is_NULL=sum(is.na(User_Score)==1),
is_NOT_NULL=sum(!is.na(User_Score)==1),
is_tbd=sum(User_Score=="tbd")
)
df %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!is.na(User_Score) & User_Score!="tbd") %>%
summarise(
Max=max(User_Score),
Min=min(User_Score),
Mean=mean(User_Score),
Median=median(User_Score),
QUA1=quantile(User_Score,1/4),
QUA3=quantile(User_Score,3/4),
IQR=IQR(User_Score)
)
df %>%
summarise(is_NULL=sum(is.na(User_Count)==1),
is_NOT_NULL=sum(!is.na(User_Count)==1)
)
df %>%
filter(!is.na(User_Count))%>%
summarise(
Max=max(User_Count),
Min=min(User_Count),
Mean=mean(User_Count),
Median=median(User_Count),
QUA1=quantile(User_Count,1/4),
QUA3=quantile(User_Count,3/4),
IQR=IQR(User_Count)
)
summary(df)
outlier_global_sales <- qplot(y = Global_Sales, ylab = "Outliers Global Sales", data = df, geom = "boxplot", fill=I("tomato")) + theme_minimal() + theme(axis.text.x = element_text(angle = 90))
outlier_global_sales
df = subset(df, select = -c(NA_Sales,EU_Sales,JP_Sales,Other_Sales))
df <- subset(df, df$Platform != "PCFX")
df <- subset(df, df$Platform != "GG")
df$Year_of_Release <- 2024 - df$Year_of_Release
names(df)[3] <- "Age"
df <- subset(df, df$Name != "" | df$Genre != "")
is.na(df) <- df == ''
df$User_Score <- as.character(df$User_Score)
df$User_Score[df$User_Score == "tbd"] <- ""
plot_missing(df)
# Convert categorical to numbers
df$User_Score=as.double(df$User_Score)
df_imputation <- data.frame(df$Age, df$Rating, df$Critic_Score, df$Critic_Count, df$User_Score, df$User_Count)
names(df_imputation) <- c("Age_imp","Rating_imp", "Critic_Score_imp", "Critic_Count_imp", "User_Score_imp", "User_Count_imp")
df_imputation$Rating_imp = factor(df_imputation$Rating_imp,
levels = c('AO', 'E', 'E10+', 'EC', 'K-A', 'M', 'RP', 'T'), labels = c(1, 2, 3, 4, 5, 6, 7, 8))
# Imputation w/ MICE
md.pattern(df_imputation)
df_imputation_imp <- mice(df_imputation, m=5, seed = 123)
df_imputation <- complete(df_imputation_imp, 1)
plot_missing(df_imputation)
# Revert numbers to categorical
df_imputation$Rating_imp = factor(df_imputation$Rating_imp,
levels = c(1, 2, 3, 4, 5, 6, 7, 8), labels = c('AO', 'E', 'E10+', 'EC', 'K-A', 'M', 'RP', 'T'))
df <- df %>% mutate(ID = row_number())
df_imputation <- df_imputation %>% mutate(ID = row_number())
df <- merge(df,df_imputation,by="ID")
df = subset(df, select = -c(ID, Rating, Age, Critic_Score, Critic_Count, User_Score, User_Count))
publisher_data <- df %>%
group_by(Publisher) %>%
summarise(count = n()) %>%
top_n(n = 10, wt = count)
publisher_charts <- ggplot(publisher_data, aes(x = Publisher, y = count, fill=count)) + geom_col(fill="orange")+
labs(title = "Top 10 Publisher", x="Publisher",y="Total") + coord_flip()
publisher_charts
genre_data <- df %>%
group_by(Genre) %>%
summarise(count = n()) %>%
top_n(n = 5, wt = count)
genre_charts <- ggplot(genre_data, aes(x = Genre, y = count, fill=count)) + geom_col(fill="red")+
labs(title = "Top 5 Genres", x="Genre",y="Total")
genre_charts
platform_data <- df %>%
group_by(Platform) %>%
summarise(count = n()) %>%
top_n(n = 5, wt = count)
platform_charts <- ggplot(platform_data, aes(x = Platform, y = count, fill=count)) + geom_col(fill="yellow")+
labs(title = "Top 5 Platform", x="Platform",y="Total")
platform_charts
qplot(x = Genre, data = df) + geom_bar(fill = "purple") + coord_flip()  + facet_wrap(~Rating_imp, nrow = 2)
qplot(x=Platform,data=df)+ geom_bar(fill="navy") + theme(axis.text = element_text) + coord_flip() + theme_minimal() + facet_wrap(~Genre,nrow=1)
qplot(x=Platform,data=df)+ geom_bar(fill="brown") + theme(axis.text = element_text) + coord_flip() + theme_minimal() + facet_wrap(~Rating_imp,nrow=1)
df1 = subset(df, select = -c(Name, Publisher, Developer))
df1 = subset(df, select = -c(Name, Publisher, Developer))
# Exp 1 - train:test 70:30, seed 555
set.seed(555)
split = sample.split(df1$Global, SplitRatio = 0.7)
train_dataset1 = subset(df1, split == TRUE)
test_dataset1 = subset(df1, split == FALSE)
# Exp 2 - train:test 70:30, seed 555, outliers removed, data scaling
Q <- quantile(df1$Global_Sales, probs=c(.25, .75), na.rm = FALSE)
iqr <- IQR(df1$Global_Sales)
df1_clean<- subset(df1, df1$Global_Sales > (Q[1] - 1.5*iqr) & df1$Global_Sales < (Q[2]+1.5*iqr))
set.seed(555)
split = sample.split(df1_clean$Global, SplitRatio = 0.7)
train_dataset2 = subset(df1_clean, split == TRUE)
test_dataset2 = subset(df1_clean, split == FALSE)
train_dataset2[,3] = scale(train_dataset2[,3], center = TRUE, scale = TRUE)
test_dataset2[,3] = scale(test_dataset2[,3], center = TRUE, scale = TRUE)
train_dataset2[,6:9] = scale(train_dataset2[,6:9], center = TRUE, scale = TRUE)
test_dataset2[,6:9] = scale(test_dataset2[,6:9], center = TRUE, scale = TRUE)
### Exp 1 - Multiple Linear Regression
regressor1 = lm(formula = Global_Sales ~ .,
data = train_dataset1)
summary(regressor1)
summ(regressor1, confint = TRUE)
y1 = predict(regressor1, train_dataset1)
table(y1, train_dataset1$Global_Sales)
y_pred1 = predict(regressor1, test_dataset1)
table(y_pred1, test_dataset1$Global_Sales)
# RMSE on training set
RMSE(y1, train_dataset1$Global_Sales)
# RMSE on test set
RMSE(y_pred1, test_dataset1$Global_Sales)
# MAE train dataset
MAE(y1, train_dataset1$Global_Sales)
# MAE test dataset
MAE(y_pred1, test_dataset1$Global_Sales)
### Exp 2 - Multiple Linear Regression
regressor2 = lm(formula = Global_Sales ~ .,
data = train_dataset2)
summary(regressor2)
summ(regressor2, confint = TRUE)
y2 = predict(regressor2, train_dataset2)
table(y2, train_dataset2$Global_Sales)
y_pred2 = predict(regressor2, test_dataset2)
table(y_pred2, test_dataset2$Global_Sales)
# RMSE on training set
RMSE(y2, train_dataset2$Global_Sales)
# RMSE on test set
RMSE(y_pred2, test_dataset2$Global_Sales)
# MAE train dataset
MAE(y2, train_dataset2$Global_Sales)
# MAE test dataset
MAE(y_pred2, test_dataset2$Global_Sales)
